
# Superhero Data Challenge ğŸ¦¸â€â™‚ï¸ğŸ¦¸â€â™€ï¸

## DescriÃ§Ã£o do Projeto

Este projeto foi desenvolvido como parte do desafio para a vaga de Engenheiro de Dados Pleno na Bettha. O objetivo do desafio foi integrar e deduplicar bases de dados de super-herÃ³is de duas ligas (Marvel e DC), criar um esquema de banco de dados analÃ­tico e implementar a soluÃ§Ã£o utilizando Python. A base analÃ­tica gerada Ã© projetada para atender as necessidades dos times de negÃ³cio em termos de visualizaÃ§Ã£o de dashboards e exploraÃ§Ã£o de iniciativas de Machine Learning, otimizando a alocaÃ§Ã£o de herÃ³is em novas missÃµes.

## Racional da SoluÃ§Ã£o

A soluÃ§Ã£o proposta foi dividida em trÃªs partes principais:

1. **IntegraÃ§Ã£o e DeduplicaÃ§Ã£o dos Dados:**
   - Os dados fornecidos em formato CSV foram integrados e deduplicados utilizando funÃ§Ãµes desenvolvidas em Python. Foram realizadas verificaÃ§Ãµes para garantir que os registros duplicados fossem removidos com base em identificadores chave como `hero_id` e `mission_id`.

2. **Proposta e ImplementaÃ§Ã£o do Esquema AnalÃ­tico:**
   - Um esquema analÃ­tico foi projetado considerando as necessidades de anÃ¡lise para a otimizaÃ§Ã£o de missÃµes e alocaÃ§Ã£o de herÃ³is. O esquema foi implementado em tabelas dimensionais (dim_heroes, dim_villains, etc.) e uma tabela fato (fato_missions).
   - As tabelas foram salvas em formato Parquet, garantindo compatibilidade com Google BigQuery e otimizando o armazenamento e o desempenho das consultas.

3. **AnÃ¡lises e VisualizaÃ§Ãµes:**
   - Foram realizadas algumas anÃ¡lises exploratÃ³rias para extrair insights dos dados, como a distribuiÃ§Ã£o dos herÃ³is por gÃªnero e a duraÃ§Ã£o mÃ©dia das missÃµes.

## Estrutura do RepositÃ³rio

O projeto estÃ¡ organizado da seguinte maneira:

```plaintext
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ landing            # Dados brutos fornecidos
â”‚   â”œâ”€â”€ raw                # Dados integrados e deduplicados
â”‚   â”œâ”€â”€ trusted            # Dados com o schema estabelecido aplicado
â”‚   â””â”€â”€ analytics          # Tabelas dim e analÃ­ticas geradas em formato Parquet para o BigQuery
â”œâ”€â”€ logs                   # Arquivos de log de execuÃ§Ã£o
â”œâ”€â”€ notebooks              # Notebooks Jupyter com algumas visualizaÃ§Ãµes
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ etl.py             # Script principal de ETL
â”‚   â”œâ”€â”€ schema.py          # Screma proposto para a modelagem dos dados
â”‚   â””â”€â”€ utils.py           # Classe utilitÃ¡ria
â””â”€â”€ README.md              # Este arquivo
```

## InstruÃ§Ãµes para Reproduzir

### 1. PrÃ©-requisitos

-**Limpeza de Dados**
- A atual estrutura jÃ¡ possui os dados processados. Caso queira rodar a pipeline, limpe os dados em data/analytics, data/raw e data/trusted. 

- **Python 3.8+** deve estar instalado.
- Instale as dependÃªncias do projeto listadas em `requirements.txt` utilizando o seguinte comando:
  
  ```bash
  pip install -r requirements.txt
  ```

### 2. Executando o Pipeline de ETL

1. **Dados:**
   - Os dados fornecidos jÃ¡ estÃ£o em `data/landing`.

2. **Executar o Script de ETL:**
   - Navegue atÃ© a pasta `src` e execute o script `etl.py` para realizar a integraÃ§Ã£o, deduplicaÃ§Ã£o, e salvar as tabelas analÃ­ticas em formato Parquet:
  
  ```bash
  python etl.py
  ```

   - O script tambÃ©m gera logs que podem ser encontrados na pasta `logs`.

### 3. Visualizando as AnÃ¡lises

- Abra o notebook Jupyter localizado na pasta `notebooks` para visualizar as anÃ¡lises realizadas. As anÃ¡lises incluem grÃ¡ficos gerados utilizando Matplotlib e fornecem insights sobre a distribuiÃ§Ã£o de herÃ³is, sucesso de missÃµes, entre outros aspectos.

### 4. Carregando os Dados no Google BigQuery

- As tabelas em formato Parquet podem ser carregadas no Google BigQuery diretamente para anÃ¡lise adicional. O esquema foi projetado para ser facilmente carregado e consultado.

## ConsideraÃ§Ãµes Finais

Este projeto demonstra o processo completo de ETL, desde a ingestÃ£o de dados brutos atÃ© a geraÃ§Ã£o de tabelas analÃ­ticas prontas para anÃ¡lise de negÃ³cios. AlÃ©m disso, inclui exemplos de visualizaÃ§Ãµes e insights Ãºteis para a tomada de decisÃµes estratÃ©gicas.

Sinta-se Ã  vontade para explorar o cÃ³digo e as anÃ¡lises, e entre em contato caso tenha alguma dÃºvida ou sugestÃ£o!
